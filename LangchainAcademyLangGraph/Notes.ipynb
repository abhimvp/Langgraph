{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b91ff19",
   "metadata": {},
   "source": [
    "## Module - 0 - Notes\n",
    "\n",
    "- Langchain made it easy to build LLM Applications , **Agents** are one of the popular LLM Applications, as we can do a lot with them & automate different types of tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eebc7ef",
   "metadata": {},
   "source": [
    "- We will be using [`Chat Models`](https://python.langchain.com/docs/concepts/chat_models/) - which do a few things `take a sequence of messages` as _inputs_ and _return_ `chat messages as outputs`.\n",
    "- Langchain ecosystem currently provides following 3rd party integrations - here is the list of [Chat Models](https://python.langchain.com/docs/integrations/chat/)\n",
    "- I will be using [ChatGoogleGenerativeAI](https://python.langchain.com/docs/integrations/chat/google_generative_ai/) by making use of GOOGLE_API_KEY(Have this in our `.env`) we get it from [here](https://aistudio.google.com/app/apikey)\n",
    "- A common and recommended practice for managing environment variables locally is to use a `.env` file & Install the `python-dotenv` library - **!uv add python-dotenv** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a21f8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m95 packages\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m89 packages\u001b[0m \u001b[2min 0.07ms\u001b[0m\u001b[0m\n",
      "\u001b[2mResolved \u001b[1m95 packages\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m89 packages\u001b[0m \u001b[2min 0.05ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv add langchain-google-genai\n",
    "!uv add python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e800c337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded and retrieved the Google API key from the .env file.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key from the environment variable\n",
    "google_api_key = os.environ.get('GOOGLE_API_KEY')\n",
    "\n",
    "if google_api_key:\n",
    "    print(\"Successfully loaded and retrieved the Google API key from the .env file.\")\n",
    "else:\n",
    "    print(\"Could not find the 'GOOGLE_API_KEY' in the .env file or the environment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58efe58",
   "metadata": {},
   "source": [
    "There are [a few standard parameters](https://python.langchain.com/docs/concepts/chat_models/#standard-parameters) that we can set with chat models. Two of the most common are:\n",
    "\n",
    "- `model`: the name of the model\n",
    "- `temperature`: the sampling temperature\n",
    "- `Temperature` controls the randomness or creativity of the model's output where low temperature (close to 0) is more deterministic and focused outputs. This is good for tasks requiring accuracy or factual responses. High temperature (close to 1) is good for creative tasks or generating varied responses.\n",
    "\n",
    "Chat models in LangChain have a number of [default methods](https://python.langchain.com/docs/concepts/chat_models/#key-methods). For the most part, we'll be using:\n",
    "\n",
    "* `stream`: stream back chunks of the response\n",
    "* `invoke`: call the chain on an input\n",
    "\n",
    "And, as mentioned, chat models take [messages](https://python.langchain.com/docs/concepts/messages/) as input. `Messages have a role` (that `describes` **who** is saying the message) and a content property. We'll be talking a lot more about this later, but here let's just show the basics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64ec9498",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0,    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a40eb0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello there! How can I help you today?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--16e4f8cc-8ddc-4dc9-aa0a-769350fef13e-0', usage_metadata={'input_tokens': 2, 'output_tokens': 11, 'total_tokens': 13, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example on working with Messages\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Create a message\n",
    "msg = HumanMessage(content=\"Hello world\", name=\"Abhishek\")\n",
    "\n",
    "# Message list\n",
    "messages = [msg]\n",
    "\n",
    "# Invoke the model with a list of messages \n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c54222f",
   "metadata": {},
   "source": [
    "We get an `AIMessage` response. Also, note that we can just invoke a chat model with a string. When a string is passed in as input, it is converted to a `HumanMessage` and then passed to the underlying model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77d0bf5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Virat Kohli is an Indian international cricketer and former captain of the Indian national cricket team. He is widely regarded as one of the greatest batsmen of all time. Here's a breakdown of his key aspects:\\n\\n*   **Cricketing Career:**\\n    *   **Batsman:** Primarily a right-handed top-order batsman. Known for his aggressive batting style, consistency, and ability to perform under pressure.\\n    *   **Captain:** He was the captain of the Indian cricket team across all three formats (Test, ODI, and T20I) for several years. He stepped down from captaincy in phases, concluding with Test captaincy in January 2022.\\n    *   **Achievements:** Holds numerous records in cricket, including:\\n        *   Most centuries in ODIs (One Day Internationals).\\n        *   Fastest to reach various milestones in terms of runs scored in both ODIs and Tests.\\n        *   Most runs in T20 Internationals.\\n        *   Most player of the series awards in Test cricket.\\n        *   Most double centuries as Test captain.\\n    *   **Teams:** Represents India internationally and has played for Royal Challengers Bangalore (RCB) in the Indian Premier League (IPL).\\n\\n*   **Personal Life:**\\n    *   Married to actress Anushka Sharma.\\n    *   Has a significant social media presence and is one of the most followed athletes globally.\\n\\n*   **Style and Personality:**\\n    *   Known for his passionate and expressive demeanor on the field.\\n    *   A fitness enthusiast and has played a role in promoting fitness culture in Indian cricket.\\n\\nIn summary, Virat Kohli is a highly accomplished cricketer, a former captain, and a prominent figure in the world of sports.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--c4c1c8e7-195f-4fda-b9dc-4a2dff9b3649-0', usage_metadata={'input_tokens': 6, 'output_tokens': 369, 'total_tokens': 375, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"who is virat kohli\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1aaf609",
   "metadata": {},
   "source": [
    "- Search Tools\n",
    "\n",
    "You'll also see [Tavily](https://app.tavily.com/home) in the README, which is a search engine optimized for LLMs and RAG, aimed at efficient, quick, and persistent search results. As mentioned, it's easy to sign up and offers a generous free tier. Some lessons (in Module 4) will use Tavily by default but, of course, other search tools can be used if you want to modify the code for yourself.\n",
    "\n",
    "[TavilySearch API Reference](https://python.langchain.com/api_reference/tavily/tavily_search/langchain_tavily.tavily_search.TavilySearch.html#tavilysearch) - Tool that queries the Tavily Search API and gets back json.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe9a567a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m95 packages\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m89 packages\u001b[0m \u001b[2min 0.05ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv add langchain_community langchain-tavily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69bf8421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded and retrieved the TAVILY API key from the .env file.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the environment variables from the .env file\n",
    "load_dotenv()\n",
    "# Get the TAVILY API key from the environment variable\n",
    "tavily_api_key = os.environ.get(\"TAVILY_API_KEY\")\n",
    "\n",
    "if tavily_api_key:\n",
    "    print(\"Successfully loaded and retrieved the TAVILY API key from the .env file.\")\n",
    "    \n",
    "else:\n",
    "    print(\"Could not find the 'TAVILY_API_KEY' in the .env file or the environment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cad8b070",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "# Initialize the TavilySearch tool\n",
    "tool = TavilySearch(\n",
    "                max_results=1,\n",
    "                topic=\"general\",\n",
    "                # include_answer=False,\n",
    "                # include_raw_content=False,\n",
    "                # include_images=False,\n",
    "                # include_image_descriptions=False,\n",
    "                # search_depth=\"basic\",\n",
    "                # time_range=\"day\",\n",
    "                # include_domains=None,\n",
    "                # exclude_domains=None,\n",
    "                # country=None\n",
    "                # include_favicon=False\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b4cca6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What happened at the last wimbledon',\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': [],\n",
       " 'results': [{'url': 'https://www.nytimes.com/athletic/live-blogs/wimbledon-2025-live-updates-day-6-scores-results/zEsDiYRO6bGB/',\n",
       "   'title': 'Wimbledon 2025 live updates: Day 6 latest with Sinner on court ...',\n",
       "   'content': \"Play has resumed on the sixth day of the 2025 Wimbledon Championships after poor weather caused delays to this morning's matches. No. 1 Jannik\",\n",
       "   'score': 0.23283345,\n",
       "   'raw_content': None}],\n",
       " 'response_time': 0.83}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.invoke({\"query\": \"What happened at the last wimbledon\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a48e4d",
   "metadata": {},
   "source": [
    "# Module - 1 - Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cc2a61",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
